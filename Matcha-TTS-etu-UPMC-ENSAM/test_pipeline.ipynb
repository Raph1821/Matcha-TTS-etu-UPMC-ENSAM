{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b9b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "# 1. Ajustement du chemin pour trouver le module 'matcha'\n",
    "root_path = r'D:\\Master_SAR\\MLA\\PJT\\Git\\Matcha-TTS-etu-UPMC-ENSAM'\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "# 2. Imports des modules de donn√©es\n",
    "from matcha.data_management.ljspeech_datamodule import LJSpeechDataModule\n",
    "from matcha.utils.utils import plot_spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c8da409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset d'entra√Ænement : 12839 √©chantillons\n",
      "Dataset de validation : 261 √©chantillons\n"
     ]
    }
   ],
   "source": [
    "# Chemin vers le dossier racine de vos donn√©es LJSpeech\n",
    "data_dir = r\"D:\\Master_SAR\\MLA\\PJT\\Git\\Matcha-TTS-etu-UPMC-ENSAM\\data\\LJSpeech-1.1\"\n",
    "\n",
    "# Initialisation\n",
    "dm = LJSpeechDataModule(data_dir=data_dir, batch_size=4, num_workers=0) # num_workers=0 est plus stable pour l'exemple\n",
    "dm.setup()\n",
    "\n",
    "print(f\"Dataset d'entra√Ænement : {len(dm.train_ds)} √©chantillons\")\n",
    "print(f\"Dataset de validation : {len(dm.val_ds)} √©chantillons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd3dbfcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\LJSpeech-1.1\\\\wavs\\\\LJ001-0022.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1. R√©cup√©ration d'un Batch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m dm\u001b[38;5;241m.\u001b[39mtrain_dataloader()  \u001b[38;5;66;03m# 1. R√©cup√®re le DataLoader d'entra√Ænement\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m      \u001b[38;5;66;03m# 2. Charge le premier batch // iter pour liste le dataset en it√©ration et next pour le premier de la liste\u001b[39;00m\n\u001b[0;32m      7\u001b[0m x, x_lens \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_lengths\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      8\u001b[0m y, y_lens \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_lengths\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Logiciel\\Miniconda3\\envs\\matcha-tts-develop\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    738\u001b[0m ):\n",
      "File \u001b[1;32md:\\Logiciel\\Miniconda3\\envs\\matcha-tts-develop\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    787\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 788\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    790\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Logiciel\\Miniconda3\\envs\\matcha-tts-develop\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Logiciel\\Miniconda3\\envs\\matcha-tts-develop\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mD:\\Master_SAR\\MLA\\PJT\\Git\\Matcha-TTS-etu-UPMC-ENSAM\\matcha\\data_management\\ljspeechDataset.py:33\u001b[0m, in \u001b[0;36mLJSpeechDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     30\u001b[0m text_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(text_to_sequence(raw_text), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 2. Traitement Audio (wav_path est d√©j√† le chemin complet gr√¢ce √† ljspeech.py)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m mel \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_process_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmel_proc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: text_ids, \n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_lengths\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlen\u001b[39m(text_ids)),\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: mel\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m), \n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_lengths\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     40\u001b[0m }\n",
      "File \u001b[1;32mD:\\Master_SAR\\MLA\\PJT\\Git\\Matcha-TTS-etu-UPMC-ENSAM\\matcha\\utils\\audio_process.py:77\u001b[0m, in \u001b[0;36mload_and_process_audio\u001b[1;34m(file_path, mel_processor)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_and_process_audio\u001b[39m(file_path, mel_processor):\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Charge le wav et le transforme en Mel en une ligne\"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     sampling_rate, data \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# Conversion en tenseur et normalisation de l'amplitude 16-bit\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(data\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)) \u001b[38;5;241m/\u001b[39m MAX_WAV_VALUE\n",
      "File \u001b[1;32md:\\Logiciel\\Miniconda3\\envs\\matcha-tts-develop\\lib\\site-packages\\scipy\\io\\wavfile.py:674\u001b[0m, in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    672\u001b[0m     mmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 674\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    677\u001b[0m     file_size, is_big_endian, is_rf64 \u001b[38;5;241m=\u001b[39m _read_riff_chunk(fid)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\LJSpeech-1.1\\\\wavs\\\\LJ001-0022.wav'"
     ]
    }
   ],
   "source": [
    "# 1. R√©cup√©ration d'un Batch\n",
    "train_loader = dm.train_dataloader()  # 1. R√©cup√®re le DataLoader d'entra√Ænement\n",
    "batch = next(iter(train_loader))      # 2. Charge le premier batch // iter pour liste le dataset en it√©ration et next pour le premier de la liste\n",
    "\n",
    "\n",
    "\n",
    "x, x_lens = batch[\"x\"], batch[\"x_lengths\"]\n",
    "y, y_lens = batch[\"y\"], batch[\"y_lengths\"]\n",
    "\n",
    "print(f\"Forme du Batch Texte (x) : {x.shape} -> [Batch, Max_Len]\")\n",
    "print(f\"Forme du Batch Mel (y)   : {y.shape} -> [Batch, 80, Max_Time]\")\n",
    "\n",
    "# 2. V√©rification du padding sur le texte\n",
    "# On cherche la phrase la plus courte du batch\n",
    "shortest_idx = torch.argmin(x_lens)\n",
    "print(f\"\\nüîç V√©rification de la phrase la plus courte (Index {shortest_idx}, Longueur r√©elle {x_lens[shortest_idx]}) :\")\n",
    "print(f\"Valeurs de fin de s√©quence : {x[shortest_idx, -5:].tolist()}\")\n",
    "\n",
    "if x[shortest_idx, -1] == 0:\n",
    "    print(\"SUCC√àS : Le padding (0) est pr√©sent en fin de s√©quence.\")\n",
    "else:\n",
    "    print(\"ATTENTION : Le dernier √©l√©ment n'est pas un 0. V√©rifiez votre fonction collate.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matcha-tts-develop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
