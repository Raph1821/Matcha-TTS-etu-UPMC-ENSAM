<div align="center">

# Matcha-TTS: A fast TTS architecture with conditional flow matching

### Mathis Lecry, Paul-Marie Demars, Yucheng DAI, Minh Nhut NGUYEN

<div align="left">

## ğŸ“‹ Table des matiÃ¨res
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Flux de DonnÃ©es Complet](#flux-de-donnÃ©es-complet)
- [Scripts disponibles](#scripts-disponibles)
- [Structure du projet](#structure-du-projet)
- [Architecture du code](#architecture-et-structure-du-code)
- [Tests et notebooks](#tests-et-notebooks)
- [Checkpoints et Logs](#checkpoints-et-logs)


## Installation

### 1. CrÃ©er l'environnement conda

Dans le terminal (cmd ou PowerShell), se placer dans le dossier du projet :

```bash
cd path/to/Matcha-TTS-etu
```

CrÃ©er et activer l'environnement :

```bash
conda create -n matcha-tts python=3.10
conda activate matcha-tts 
```

### 2. Installer les dÃ©pendances

Assurez-vous d'Ãªtre dans le dossier racine du projet (oÃ¹ se trouve `requirements.txt`) :

```bash
pip install -r requirements.txt
```

### 3. (Optionnel) Compiler les modules Cython

Pour de meilleures performances (recommandÃ©) :
Le module `monotonic_align` est critique pour les performances. Il calcule l'alignement optimal entre le texte et l'audio.

**Sans Cython :** Version Python pure (lente)  
**Avec Cython :** Version compilÃ©e en C (10-100x plus rapide)

```bash
pip install Cython
python compiler_cython.py
```

Cela compile le module d'alignement monotone (`monotonic_align`) en C pour accÃ©lÃ©rer l'entraÃ®nement.
Voir [README_CYTHON](guide_book/README_CYTHON.md) pour plus de dÃ©tails.

### 4. PrÃ©parer les donnÃ©es

Le dataset LJSpeech doit Ãªtre tÃ©lÃ©chargÃ© et placÃ© dans un dossier `data/` Ã  **la racine du projet** :

```
Matcha-TTS-etu/
â”œâ”€â”€ train.py
â”œâ”€â”€ README.md
â”œâ”€â”€ matcha/
â””â”€â”€ data/                  â† Ã€ crÃ©er
    â””â”€â”€ LJSpeech-1.1/      â† Dataset Ã  tÃ©lÃ©charger
        â”œâ”€â”€ metadata.csv
        â””â”€â”€ wavs/
```

**TÃ©lÃ©chargement du dataset :**

Option 1 - Script automatique :
```bash
# Utiliser le script de tÃ©lÃ©chargement (si disponible)
python -m matcha.utils.data_download.ljspeech
```

Option 2 - Manuel :
1. TÃ©lÃ©charger depuis : https://keithito.com/LJ-Speech-Dataset/
2. Extraire l'archive
3. CrÃ©er le dossier `data/` Ã  la racine du projet
4. Placer le dossier `LJSpeech-1.1/` dans `data/`


## Utilisation

### EntraÃ®nement complet

```bash
# 1. Lancer l'entraÃ®nement
python train.py 
```
OU
```bash
# 2. Forcer un nouveau dÃ©part
python train.py --no-resume
```

### GÃ©nÃ©ration audio

```bash
# MÃ©thode 1 : Griffin-Lim (rapide mais qualitÃ© moyenne)
python generate.py

# MÃ©thode 2 : HiFi-GAN (meilleure qualitÃ©)
python generate_HifiGan.py
```

### Analyse des rÃ©sultats

```bash
# GÃ©nÃ©rer les graphiques de mÃ©triques
python analyze_training.py

# Visualiser avec TensorBoard
tensorboard --logdir lightning_logs
```
## Flux de DonnÃ©es Complet

```
1. Texte brut : "Hello world"
   â†“
2. [text_to_sequence] â†’ Tokens : [34, 12, 45, ...]
   â†“
3. [TextEncoder] â†’ Vecteurs h : [batch, n_tokens, 192]
   â†“
4. [Duration Predictor] â†’ DurÃ©es : [5, 3, 7, ...]
   â†“
5. [Upsampling] â†’ h alignÃ© : [batch, 192, T_audio]
   â†“
6. [Decoder + Flow Matching] â†’ Mel : [batch, 80, T_audio]
   â†“
7. [Vocoder Griffin-Lim/HiFi-GAN] â†’ Audio : waveform
   â†“
8. Fichier WAV sauvegardÃ©
```

## Scripts disponibles

### `train.py` - EntraÃ®nement

Lance l'entraÃ®nement du modÃ¨le Matcha-TTS.

**Utilisation basique :**
```bash
python train.py
```

**Options :**
```bash
python train.py --checkpoint path/to/checkpoint.ckpt  # Reprendre depuis un checkpoint
python train.py --no-resume                           # Forcer le dÃ©marrage depuis zÃ©ro
```

**FonctionnalitÃ©s :**
- DÃ©tection automatique du dernier checkpoint
- Reprise d'entraÃ®nement avec Ã©tat complet (epoch, step, optimiseur)
- Sauvegarde automatique des 3 meilleurs modÃ¨les + le dernier
- Logs TensorBoard dans `lightning_logs/`
- Gradient clipping et accumulation

**Configuration :**
- Max epochs : 1000
- Batch size : 16
- Precision : 32-bit
- GPU : 1 device
- Accumulation : 2 batches

### `generate.py` - GÃ©nÃ©ration audio (Griffin-Lim)

GÃ©nÃ¨re de l'audio Ã  partir de texte en utilisant Griffin-Lim pour la reconstruction.

**Configuration dans le script :**
```python
CHECKPOINT_PATH = None  # Auto-dÃ©tection du dernier checkpoint
OUTPUT_FOLDER = "generated_audio"
TEXTE_A_DIRE = "Hello, I am your Matcha Text to Speech model."
```

**Utilisation :**
```bash
python generate.py
```

**Sorties :**
- `generated_audio/test_matcha.wav` : Fichier audio
- `generated_audio/mel_spectrogram.png` : Visualisation

**Processus :**
1. Charge le checkpoint entraÃ®nÃ©
2. Convertit le texte en tokens
3. GÃ©nÃ¨re le spectrogramme Mel via Flow Matching
4. Reconstruit l'audio avec InverseMelScale + Griffin-Lim

### `generate_HifiGan.py` - GÃ©nÃ©ration audio (HiFi-GAN)

Version alternative utilisant le vocoder HiFi-GAN pour une meilleure qualitÃ© audio.

```bash
python generate_HifiGan.py
```

### `analyze_training.py` - Analyse des logs

Extrait et visualise les mÃ©triques d'entraÃ®nement depuis TensorBoard.

**Utilisation :**
```bash
python analyze_training.py
```

**Sorties dans `training_analysis/` :**
- `all_metrics.csv` : Toutes les mÃ©triques en format tableau
- `loss_train.png` : Ã‰volution de la loss d'entraÃ®nement
- `loss_val.png` : Ã‰volution de la loss de validation
- `learning_rate.png` : Ã‰volution du learning rate
- `comparison_train_val.png` : Comparaison train/val
- Autres mÃ©triques disponibles

### `compiler_cython.py` - Compilation Cython

Compile les modules Cython pour optimiser les performances.

```bash
python compiler_cython.py
```

Compile spÃ©cifiquement `matcha/utils/monotonic_align/core.pyx` qui est utilisÃ© pour l'alignement texte-audio.

### `test_monotonic_align_speed.py` - Test de performance

Compare la vitesse entre la version Python et Cython de l'alignement monotone.

```bash
python test_monotonic_align_speed.py
```

### `test_pipeline.ipynb` - Test du pipeline

Notebook Jupyter pour tester le pipeline complet de bout en bout.

## Structure du projet

```
Matcha-TTS-etu/
â”‚
â”œâ”€â”€ ğŸ“„ Scripts principaux
â”‚   â”œâ”€â”€ train.py                      # EntraÃ®nement du modÃ¨le
â”‚   â”œâ”€â”€ generate.py                   # GÃ©nÃ©ration audio (Griffin-Lim)
â”‚   â”œâ”€â”€ generate_HifiGan.py          # GÃ©nÃ©ration audio (HiFi-GAN)
â”‚   â”œâ”€â”€ analyze_training.py          # Analyse des mÃ©triques d'entraÃ®nement
â”‚   â”œâ”€â”€ compiler_cython.py           # Compilation Cython
â”‚   â””â”€â”€ test_monotonic_align_speed.py # Test de performance
â”‚
â”œâ”€â”€ ğŸ“„ Configuration
â”‚   â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”‚   â”œâ”€â”€ setup.py                     # Installation du package
â”‚   â”œâ”€â”€ checkpts/config.json         # Configuration du modÃ¨le
â”‚   â””â”€â”€ .gitignore
â”‚
â”œâ”€â”€ ğŸ“„ Documentation
â”‚   â”œâ”€â”€ README.md                    # Ce fichier
â”‚   â”œâ”€â”€ CHANGELOG.md                 # Historique des modifications
â”‚   â””â”€â”€ guide_book/                  # Guides et documentation dÃ©taillÃ©e
â”‚       â”œâ”€â”€ ARCHITECTURE_PROTOCOL.md # Protocole d'architecture dÃ©taillÃ©
â”‚       â””â”€â”€ README_CYTHON.md         # Documentation Cython
â”‚
â”œâ”€â”€ ğŸ“ matcha/                       # Package principal
â”‚   â”œâ”€â”€ models/                      # ModÃ¨les neuronaux
â”‚   â”‚   â”œâ”€â”€ matcha_tts.py           # Classe principale MatchaTTS
â”‚   â”‚   â”œâ”€â”€ baselightningmodule.py  # Module de base Lightning
â”‚   â”‚   â””â”€â”€ components/             # Composants du modÃ¨le
â”‚   â”‚       â”œâ”€â”€ text_encoder.py     # Encodeur de texte (Transformer)
â”‚   â”‚       â”œâ”€â”€ decoder.py          # DÃ©codeur U-Net
â”‚   â”‚       â”œâ”€â”€ flow_matching.py    # Algorithme Flow Matching
â”‚   â”‚       â””â”€â”€ transformer.py      # Blocs Transformer
â”‚   â”‚
â”‚   â”œâ”€â”€ data_management/            # Gestion des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ ljspeechDataset.py     # Dataset PyTorch
â”‚   â”‚   â””â”€â”€ ljspeech_datamodule.py # DataModule Lightning
â”‚   â”‚
â”‚   â”œâ”€â”€ text_to_ID/                # Traitement du texte
â”‚   â”‚   â”œâ”€â”€ text_to_sequence.py    # Conversion texte â†’ tokens
â”‚   â”‚   â”œâ”€â”€ cleaners.py            # Nettoyage du texte
â”‚   â”‚   â”œâ”€â”€ symbols.py             # Vocabulaire
â”‚   â”‚   â”œâ”€â”€ numbers.py             # Conversion nombres â†’ texte
â”‚   â”‚   â”œâ”€â”€ cmudict.py             # Dictionnaire phonÃ©tique
â”‚   â”‚   â””â”€â”€ cmudict-0.7b           # DonnÃ©es CMU
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                     # Utilitaires
â”‚   â”‚   â”œâ”€â”€ audio_process.py       # Traitement audio
â”‚   â”‚   â”œâ”€â”€ model.py               # Utilitaires modÃ¨le
â”‚   â”‚   â”œâ”€â”€ utils.py               # Fonctions diverses
â”‚   â”‚   â”œâ”€â”€ monotonic_align/       # Alignement monotone (Cython)
â”‚   â”‚   â””â”€â”€ data_download/         # TÃ©lÃ©chargement donnÃ©es
â”‚   â”‚
â”‚   â”œâ”€â”€ tests_text/                # Tests unitaires
â”‚   â””â”€â”€ hifigan/                   # Vocoder HiFi-GAN
â”‚
â”œâ”€â”€ ğŸ“ hifi_gan/                    # Vocoder HiFi-GAN alternatif
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ env.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                   # Notebooks Jupyter
â”‚   â”œâ”€â”€ test_audio_to_Mel.ipynb
â”‚   â””â”€â”€ test_text.ipynb
â”‚
â””â”€â”€ ğŸ“ lightning_logs/              # Logs et checkpoints
    â””â”€â”€ version_X/checkpoints/      # ModÃ¨les sauvegardÃ©s (.ckpt)
```

## Architecture et Structure du Code

### 1. Le CÅ“ur du ModÃ¨le : `matcha/models/matcha_tts.py`

Ce fichier contient la classe principale **`MatchaTTS`**. C'est le "cerveau" du projet qui hÃ©rite de **`LightningModule`** (PyTorch Lightning).

**Son rÃ´le :** Il assemble les briques fondamentales.

**Ce qu'il contient :**
- **Text Encoder :** Convertit le texte en vecteurs contextuels
- **Decoder (U-Net) :** ImplÃ©mente le Flow Matching pour transformer le bruit en spectrogramme
- **Fonction de perte (Loss) :** Calcule l'erreur de prÃ©diction du champ de vecteurs
- **Optimiseur :** AdamW avec learning rate scheduler

**MÃ©thodes clÃ©s :**
- `forward()` : Passe avant pour l'entraÃ®nement
- `synthesise()` : GÃ©nÃ©ration audio (infÃ©rence)
- `training_step()` / `validation_step()` : Gestion Lightning

### 2. La Gestion des DonnÃ©es : `matcha/data_management/`

Ce dossier prÃ©pare le "carburant" du modÃ¨le.

**`ljspeechDataset.py` (Le Dataset) :**
- Lit les fichiers audio `.wav` et transcriptions `.txt`
- Transforme l'audio en **Mel-Spectrogramme** (80 bins)
- Nettoie et tokenise le texte
- Applique la normalisation

**`ljspeech_datamodule.py` (Le DataModule) :**
- Organise les donnÃ©es en batches
- Divise en Train (90%) / Val (5%) / Test (5%)
- GÃ¨re le parallÃ©lisme avec `num_workers`
- Configure pin_memory et persistent_workers

### 3. Les Composants : `matcha/models/components/`

**`text_encoder.py` - Encodage linguistique**
- Embedding des tokens de texte
- Transformer avec attention multi-tÃªtes
- PrÃ©diction des durÃ©es phonÃ©tiques
- Upsampling vers la dimension temporelle

**`decoder.py` - DÃ©codeur U-Net**
- Architecture U-Net avec skip connections
- ConditionnÃ© par le temps (timestep embedding)
- PrÃ©dit le champ de vecteurs pour le Flow Matching
- Utilise des blocs Conformer/Transformer

**`flow_matching.py` - Flow Matching**
- ImplÃ©mente l'ODE conditionnelle
- RÃ©solution par mÃ©thode d'Euler
- Transforme bruit â†’ spectrogramme Mel
- ContrÃ´le par tempÃ©rature et steps

**`transformer.py` - Blocs Transformer**
- Multi-Head Attention
- Feed-Forward Networks
- Layer Normalization
- Positional Encoding

### 4. Le Traitement du Texte : `matcha/text_to_ID/`

**Pipeline de conversion :**
```
Texte brut â†’ Cleaning â†’ Normalisation â†’ PhonÃ©misation â†’ Tokens
```

- **`cleaners.py`** : Minuscules, suppression accents, normalisation
- **`numbers.py`** : "123" â†’ "one hundred twenty three"
- **`cmudict.py`** : Dictionnaire phonÃ©tique anglais
- **`text_to_sequence.py`** : Orchestration complÃ¨te
- **`symbols.py`** : Vocabulaire (lettres, phonÃ¨mes, ponctuation)

### 5. Les Utilitaires : `matcha/utils/`

**`audio_process.py` - Traitement audio**
- STFT (Short-Time Fourier Transform)
- Conversion vers Mel-spectrogram
- Normalisation / DÃ©normalisation
- ParamÃ¨tres : n_fft=1024, hop_length=256, n_mels=80

**`monotonic_align/` - Alignement optimisÃ©**
- Version Cython ultra-rapide
- Aligne le texte avec les frames audio
- UtilisÃ© pendant l'entraÃ®nement

## Tests et Notebooks

### Notebooks disponibles

1. **`test_text.ipynb`** : Test du pipeline de traitement texte
   - Nettoyage
   - PhonÃ©misation
   - Tokenisation

2. **`test_audio_to_Mel.ipynb`** : Test de conversion audio
   - Chargement WAV
   - STFT
   - Mel-spectrogram

3. **`test_pipeline.ipynb`** : Test du pipeline complet
   - Chargement donnÃ©es
   - Forward pass
   - GÃ©nÃ©ration

### Tests unitaires

```bash
# Tests dans matcha/tests_text/
python -m pytest matcha/tests_text/
```

## Checkpoints et Logs

### Structure des logs

```
lightning_logs/
â”œâ”€â”€ version_0/          # Premier entraÃ®nement
â”œâ”€â”€ version_1/          # DeuxiÃ¨me entraÃ®nement
â””â”€â”€ version_N/          # N-iÃ¨me entraÃ®nement
    â”œâ”€â”€ checkpoints/
    â”‚   â”œâ”€â”€ best-epoch=XX-loss=Y.YYY.ckpt  # Meilleurs modÃ¨les (top 3)
    â”‚   â””â”€â”€ last-epoch=XX-step=YYYY.ckpt   # Dernier checkpoint
    â”œâ”€â”€ events.out.tfevents.xxxxx          # TensorBoard
    â””â”€â”€ hparams.yaml                       # HyperparamÃ¨tres
```

### MÃ©triques sauvegardÃ©es

- `loss/train` : Loss d'entraÃ®nement
- `loss/val` : Loss de validation
- `learning_rate` : Taux d'apprentissage
- `epoch` : NumÃ©ro d'Ã©poque
- Custom metrics si ajoutÃ©es

## Notes importantes

- **GPU recommandÃ©** : L'entraÃ®nement sur CPU est trÃ¨s lent
- **MÃ©moire** : Minimum 8GB de RAM, 4GB de VRAM GPU
- **Dataset** : LJSpeech (~2.5GB) recommandÃ© pour dÃ©buter
- **Temps d'entraÃ®nement** : Plusieurs heures Ã  jours selon GPU
- **QualitÃ© audio** : Griffin-Lim = rapide mais qualitÃ© moyenne, HiFi-GAN = meilleure qualitÃ©

---

## ğŸ‘¥ Contributeurs

- Mathis Lecry
- Paul-Marie Demars
- Yucheng DAI
- Minh Nhut NGUYEN