# Journal des modifications - Version de reproduction Matcha-TTS

Ce document d√©taille toutes les modifications apport√©es depuis la version originale de Matcha-TTS jusqu'√† la version de reproduction actuelle.

## üìã Vue d'ensemble des modifications

L'objectif principal de ces modifications est de **reproduire** (et non copier) l'architecture compl√®te de Matcha-TTS originale, de corriger les composants cl√©s manquants dans la version de d√©veloppement, tout en maintenant la flexibilit√© et la robustesse du code.

## üÜï I. Fichiers ajout√©s

### 1. `matcha/utils/monotonic_align/__init__.py`
**Fonction** : Interface Python du module MAS (Monotonic Alignment Search)

**Caract√©ristiques** :
- Fournit la fonction `maximum_path()` pour l'alignement texte-audio
- Contient une impl√©mentation de repli Python (lorsque l'extension Cython n'est pas disponible)
- G√®re automatiquement les √©checs d'importation Cython

**M√©thode d'impl√©mentation** : Version de reproduction avec gestion d'erreurs d√©taill√©e et m√©canisme de repli

---

### 2. `matcha/utils/monotonic_align/core.pyx`
**Fonction** : Impl√©mentation optimis√©e Cython de l'algorithme MAS

**Caract√©ristiques** :
- Utilise Cython pour acc√©l√©rer les calculs d'alignement
- Contient des cha√Ænes de documentation et commentaires d√©taill√©s
- Format et structure du code ajust√©s (reproduction plut√¥t que copie)

**Fonctions cl√©s** :
- `maximum_path_each()` : Calcule le chemin d'alignement monotone pour un seul √©chantillon
- `maximum_path_c()` : Traitement parall√®le par lots de plusieurs √©chantillons

---

### 3. `matcha/utils/model.py` (ÈáçÊûÑÁâàÊú¨)

#### Am√©liorations de refactorisation
- ‚úÖ Refactorise toutes les impl√©mentations de fonctions, am√©liore les noms de variables et la structure du code
- ‚úÖ Ajoute la documentation en fran√ßais
- ‚úÖ Maintient la compatibilit√© ascendante (via des alias de fonctions)
- ‚úÖ Am√©liore la lisibilit√© et la maintenabilit√© du code

**Fonctions principales (nouveaux noms)** :
- `create_sequence_mask()` : Cr√©e un masque de s√©quence
- `build_alignment_path()` : G√©n√®re un chemin d'alignement bas√© sur la dur√©e
- `compute_duration_loss()` : Calcule la perte de dur√©e
- `apply_normalization()` / `apply_denormalization()` : Normalisation et d√©normalisation des donn√©es
- `adjust_length_for_downsampling()` : Ajuste la longueur pour la compatibilit√© avec le sous-√©chantillonnage

**Compatibilit√© ascendante** :
- Conserve les anciens noms de fonctions comme alias (`sequence_mask`, `generate_path`, `duration_loss`, `normalize`, `denormalize`, `fix_len_compatibility`)
- Le code existant peut √™tre utilis√© sans modification

---

### 4. `matcha/utils/pylogger.py`
**Fonction** : Module utilitaire de journalisation

**Caract√©ristiques** :
- Support de la journalisation pour l'entra√Ænement multi-GPU
- Contient un repli lorsque pytorch_lightning n'est pas disponible
- Utilise le d√©corateur `rank_zero_only` pour √©viter la duplication des logs

#### Am√©liorations de refactorisation r√©centes
- ‚úÖ **Optimisation de la structure du code** : Divise la logique d'application du d√©corateur en fonctions ind√©pendantes
  - `_create_noop_decorator()` : Cr√©e un d√©corateur no-op (lorsque rank_zero_only n'est pas disponible)
  - `_apply_rank_zero_filter()` : Applique le filtre rank-zero √† toutes les m√©thodes de journalisation
- ‚úÖ **Am√©lioration de la m√©thode d'import** : Supporte deux chemins d'import (`pytorch_lightning` et `lightning`) avec try-except imbriqu√©s
- ‚úÖ **Am√©lioration des noms de variables** : `name` ‚Üí `logger_name`, `logger` ‚Üí `logger_instance`, am√©liore la lisibilit√© du code
- ‚úÖ **Am√©lioration de la maintenabilit√©** : Structure du code plus claire, plus facile √† comprendre et √† maintenir

---

### 5. `matcha/models/baselightningmodule.py`
**Fonction** : Classe de base PyTorch Lightning

**Caract√©ristiques** :
- Fournit un flux d'entra√Ænement/validation g√©n√©rique
- Supporte deux m√©thodes : objets de configuration originaux et param√®tres simplifi√©s
- G√®re automatiquement la configuration de l'optimiseur et du planificateur de taux d'apprentissage
- Contient des fonctionnalit√©s de visualisation √† la fin de la validation

**M√©thodes cl√©s** :
- `update_data_statistics()` : Met √† jour les statistiques des donn√©es
- `configure_optimizers()` : Configure l'optimiseur (supporte deux m√©thodes)
- `get_losses()` : Obtient le dictionnaire des pertes
- `training_step()` / `validation_step()` : √âtapes d'entra√Ænement et de validation

---

### 6. `matcha/models/components/transformer.py`
**Fonction** : Impl√©mentation de BasicTransformerBlock (pour l'U-Net du Decoder)

**Caract√©ristiques** :
- Supporte BasicTransformerBlock de la biblioth√®que diffusers
- Contient une impl√©mentation de repli compl√®te (lorsque diffusers n'est pas disponible)
- Supporte plusieurs fonctions d'activation : GELU, GEGLU, SnakeBeta, etc.
- Corrige le traitement de la fonction d'activation "snake"

**Classes cl√©s** :
- `SnakeBeta` : Variante de la fonction d'activation Snake
- `FeedForward` : Couche de r√©seau feed-forward
- `BasicTransformerBlock` : Bloc Transformer (avec support de repli)

---

## üîÑ II. Fichiers compl√®tement r√©√©crits

### 1. `matcha/models/components/text_encoder.py`

#### Probl√®mes de la version originale
- ‚ùå Utilisait le format seq-first `[B, T, C]`, n√©cessitant de fr√©quentes transpositions
- ‚ùå Manquait DurationPredictor (impossible de pr√©dire la dur√©e des phon√®mes)
- ‚ùå Manquait RotaryPositionalEmbeddings (RoPE)
- ‚ùå Manquait prenet (r√©seau de pr√©traitement)
- ‚ùå Utilisait MultiHeadAttention standard bas√© sur Linear

#### Am√©liorations de la version de reproduction
- ‚úÖ Utilise le format Conv1d `[B, C, T]` (coh√©rent avec la version originale)
- ‚úÖ Ajoute `DurationPredictor` : Pr√©dit la dur√©e de chaque phon√®me
- ‚úÖ Ajoute `RotaryPositionalEmbeddings (RoPE)` : Encodage de position rotatif
- ‚úÖ Ajoute `prenet` : R√©seau de pr√©traitement (ConvReluNorm)
- ‚úÖ Utilise `MultiHeadAttention` bas√© sur Conv1d (avec support RoPE)
- ‚úÖ Impl√©mente les classes compl√®tes `Encoder` et `TextEncoder`

#### Nouveaux composants
- `LayerNorm` : Normalisation de couche personnalis√©e
- `ConvReluNorm` : Bloc Convolution + ReLU + Normalisation
- `DurationPredictor` : Pr√©dicteur de dur√©e
- `RotaryPositionalEmbeddings` : Encodage de position RoPE
- `MultiHeadAttention` : Attention multi-t√™tes bas√©e sur Conv1d (avec support RoPE)
- `FFN` : R√©seau feed-forward
- `Encoder` : Empilement d'encodeurs Transformer
- `TextEncoder` : Encodeur de texte complet

**Valeur de retour** : `(mu, logw, x_mask)` - Trois valeurs (corrige le probl√®me de valeur de retour de la version de d√©veloppement originale)

---

### 2. `matcha/models/components/decoder.py`

#### Probl√®mes de la version originale
- ‚ùå Seulement un empilement simple de DecoderBlock
- ‚ùå Pas de structure U-Net
- ‚ùå Manquait les connexions skip
- ‚ùå Architecture trop simplifi√©e

#### Am√©liorations de la version de reproduction
- ‚úÖ Impl√©mente l'architecture U-Net compl√®te (down blocks ‚Üí mid blocks ‚Üí up blocks)
- ‚úÖ Ajoute `ResnetBlock1D`, `Block1D`, `Downsample1D`, `Upsample1D`
- ‚úÖ Ajoute `TimestepEmbedding`, `SinusoidalPosEmb`
- ‚úÖ Ajoute les connexions skip (corrige les probl√®mes de correspondance de taille)
- ‚úÖ Supporte `ConformerWrapper` (optionnel)
- ‚úÖ Corrige le traitement de la taille du masque lors du sous-√©chantillonnage/sur-√©chantillonnage

#### Nouveaux composants
- `SinusoidalPosEmb` : Encodage de position sinuso√Ødal
- `Block1D` : Bloc de convolution 1D
- `ResnetBlock1D` : Bloc r√©siduel (avec embedding temporel)
- `Downsample1D` / `Upsample1D` : Couches de sous-√©chantillonnage et sur-√©chantillonnage
- `TimestepEmbedding` : Embedding de pas de temps
- `ConformerWrapper` : Enveloppe de bloc Conformer (optionnel)
- `Decoder` : D√©codeur U-Net complet

**Corrections cl√©s** :
- Corrige les probl√®mes de correspondance de taille des connexions skip
- Am√©liore la logique de traitement du masque lors du sous-√©chantillonnage/sur-√©chantillonnage
- Ajoute des m√©canismes de v√©rification et d'ajustement automatique de la taille

---

### 3. `matcha/models/components/flow_matching.py`

#### Probl√®mes de la version originale
- ‚ùå Seulement une classe de m√©thodes statiques
- ‚ùå Manquait l'impl√©mentation CFM compl√®te
- ‚ùå Pas de m√©thode `solve_euler`

#### Am√©liorations de la version de reproduction
- ‚úÖ Impl√©mente la classe de base `BASECFM` compl√®te
- ‚úÖ Impl√©mente la classe `CFM` (Flow Matching complet)
- ‚úÖ Ajoute la m√©thode `_solve_ode_euler()` (utilis√©e pour l'inf√©rence, m√©thode priv√©e)
- ‚úÖ Ajoute la m√©thode `compute_loss()` (calcul de perte complet)
- ‚úÖ Int√®gre Decoder comme estimateur
- ‚úÖ **Compatibilit√© arri√®re** : `compute_loss()` supporte deux API (ancienne `x1/mask/mu` et nouvelle `target_sample/target_mask/encoder_output`)
- ‚úÖ **Optimisation de la structure du code** : Divise la logique en m√©thodes auxiliaires (`_initialize_noise`, `_create_time_steps`, `_sample_random_time`, `_build_conditional_path`, `_compute_velocity_target`)

#### Corrections r√©centes (am√©lioration de la compatibilit√© arri√®re)
- ‚úÖ **Correction du TypeError lors de l'entra√Ænement** : R√©sout le probl√®me o√π `compute_loss()` recevait un argument de mot-cl√© inattendu `x1`
- ‚úÖ **Support double API** : La m√©thode `compute_loss()` accepte maintenant √† la fois les anciens noms de param√®tres (`x1`, `mask`, `mu`, `spks`, `cond`) et les nouveaux (`target_sample`, `target_mask`, `encoder_output`, `speaker_emb`, `condition`)
- ‚úÖ **Mapping automatique des param√®tres** : Si les nouveaux param√®tres sont `None`, r√©cup√®re automatiquement les valeurs des anciens param√®tres, garantissant que le code existant fonctionne sans modification
- ‚úÖ **Am√©lioration de la gestion d'erreurs** : Si aucune des deux API ne fournit les param√®tres n√©cessaires, lance un message d'erreur clair

**M√©thodes cl√©s** :
- `forward()` : Diffusion avant (utilis√©e lors de l'inf√©rence)
- `_solve_ode_euler()` : Solveur Euler (r√©solution ODE, m√©thode priv√©e)
- `compute_loss()` : Calcule la perte Flow Matching (support des anciennes et nouvelles API)

**M√©thodes auxiliaires** :
- `_initialize_noise()` : Initialise le bruit al√©atoire
- `_create_time_steps()` : Cr√©e la s√©quence de pas de temps
- `_sample_random_time()` : √âchantillonne un temps al√©atoire
- `_build_conditional_path()` : Construit le chemin conditionnel
- `_compute_velocity_target()` : Calcule la cible du champ de vitesse

---

### 4. `matcha/models/components/text_encoder.py` (ÈáçÊûÑÁâàÊú¨)

#### Am√©liorations de refactorisation
- ‚úÖ Restructure le code, am√©liore les noms de variables pour la lisibilit√©
- ‚úÖ Ajoute des m√©thodes auxiliaires, am√©liore l'organisation du code
- ‚úÖ Ajoute la documentation en fran√ßais
- ‚úÖ Maintient la compatibilit√© fonctionnelle et la coh√©rence de l'API

**Am√©liorations principales** :
- Noms de variables : `channels` ‚Üí `feature_dim`/`channel_dim`, `n_heads` ‚Üí `num_heads`, `p_dropout` ‚Üí `dropout_rate`
- Refactorisation des m√©thodes : `attention` ‚Üí `_compute_attention`, `_neg_half` ‚Üí `_apply_neg_half_transform`
- Organisation du code : divise les m√©thodes complexes, ajoute une d√©composition claire des √©tapes
- Documentation : ajoute des cha√Ænes de documentation en fran√ßais, reste concise

---

### 5. `matcha/models/matcha_tts.py`

#### Probl√®mes de la version originale
- ‚ùå Seulement Flow Matching Loss
- ‚ùå Manquait Duration Loss
- ‚ùå Manquait Prior Loss
- ‚ùå Sur-√©chantillonnage direct, pas de m√©canisme d'alignement

#### Am√©liorations de la version de reproduction
- ‚úÖ Ajoute trois fonctions de perte :
  - **Duration Loss** : Dur√©e pr√©dite vs dur√©e align√©e par MAS
  - **Prior Loss** : Diff√©rence entre mel et sortie de l'encodeur
  - **Flow Matching Loss** : Perte de pr√©diction du champ de vitesse
- ‚úÖ Ajoute le m√©canisme d'alignement MAS (Monotonic Alignment Search)
- ‚úÖ Ajoute la m√©thode `synthesise()` (flux d'inf√©rence complet)
- ‚úÖ Ajoute la m√©thode `forward()` (flux d'entra√Ænement complet)
- ‚úÖ **Supporte deux m√©thodes d'initialisation** :
  - M√©thode d'objet de configuration originale (compatible Hydra)
  - M√©thode de param√®tres simplifi√©s (`n_vocab`, `out_channels`, `hidden_channels`)

**Fonctionnalit√©s cl√©s** :
- D√©tection automatique de la m√©thode d'initialisation (objet de configuration vs param√®tres simplifi√©s)
- Flux d'entra√Ænement complet (inclut alignement et trois pertes)
- Flux d'inf√©rence complet (inclut pr√©dicteur de dur√©e et alignement)

---

## ‚úèÔ∏è III. Fichiers modifi√©s

### 1. `matcha/utils/utils.py`

**Nouvelles fonctionnalit√©s** :
- `plot_tensor()` : Convertit un tenseur en tableau d'images (pour l'enregistrement des logs)
- `save_figure_to_numpy()` : Convertit une figure matplotlib en tableau numpy

**Am√©liorations** :
- Compatible avec diff√©rentes versions de matplotlib
- Am√©lioration de la gestion des erreurs
- Ajout de commentaires d√©taill√©s en fran√ßais

#### Am√©liorations de fonctionnalit√©s r√©centes
- ‚úÖ **Am√©lioration de `save_figure_to_numpy()`** :
  - Version originale utilisait `np.fromstring()` d√©pr√©ci√©, supportait uniquement l'ancienne version de matplotlib
  - Version actuelle utilise `np.frombuffer()` (m√©thode recommand√©e)
  - Compatible avec les anciennes et nouvelles versions de matplotlib (gestion try-except)
  - Supporte la conversion RGBA vers RGB (les nouvelles versions de matplotlib utilisent buffer_rgba)
- ‚úÖ **Am√©lioration de `plot_tensor()`** :
  - Version originale acceptait uniquement les tableaux numpy, sans v√©rification de type
  - Version actuelle supporte `torch.Tensor` et `numpy.ndarray`
  - Traitement automatique de la dimension batch (prend automatiquement le premier √©chantillon si `ndim == 3`)
  - Ajoute la v√©rification et validation des erreurs (lance une exception claire si `ndim != 2`)
- ‚úÖ **Am√©lioration de la robustesse** : Meilleure gestion des erreurs, support de types plus large, support de versions plus compatible

---

### 2. `matcha/utils/__init__.py`

**Modifications** :
- Ajoute l'export de `pylogger`

---

### 3. `matcha/__init__.py`

**Modifications** :
- Ajoute l'export de `utils`

---

### 4. `train.py`

**Nouvelles fonctionnalit√©s** :
- ‚úÖ Supporte la reprise de l'entra√Ænement depuis un checkpoint
- ‚úÖ Recherche automatique du dernier checkpoint
- ‚úÖ Support des arguments en ligne de commande
- ‚úÖ Sauvegarde automatique des meilleurs mod√®les et du dernier mod√®le
- ‚úÖ Gestion d'erreurs compl√®te (d√©marrage automatique depuis le d√©but si le checkpoint n'existe pas)

**Optimisations de configuration d'entra√Ænement** :
- D√©coupage de gradient (`gradient_clip_val=1.0`) : pr√©vient l'explosion du gradient
- Accumulation de gradient (`accumulate_grad_batches=2`) : augmente efficacement la taille du batch
- Optimisation du chargement des donn√©es : `pin_memory=False` et `persistent_workers=False`, √©vite les erreurs de r√©initialisation de connexion en environnement multi-processus
- Strat√©gie de points de contr√¥le : surveillance de la perte de validation, sauvegarde des 3 meilleurs mod√®les et du dernier mod√®le

**Nouvelles fonctions** :
- `find_latest_checkpoint()` : Trouve le dernier fichier checkpoint (recherche r√©cursive et tri par date de modification)

**Arguments en ligne de commande** :
- `--checkpoint` : Sp√©cifie le chemin du checkpoint
- `--no-resume` : Force le d√©marrage depuis le d√©but

**Exemples d'utilisation** :
```bash
# Recherche automatique du dernier checkpoint
python train.py

# Sp√©cifier un checkpoint
python train.py --checkpoint path/to/checkpoint.ckpt

# Depuis le d√©but
python train.py --no-resume
```

---

### 5. `generate.py`

**Corrections** :
- ‚úÖ Corrige l'erreur de d√©ballage de la valeur de retour de `TextEncoder` (de 2 √† 3 valeurs)
- ‚úÖ Utilise la m√©thode `model.synthesise()` (flux d'inf√©rence complet)
- ‚úÖ Am√©liore la logique de traitement du mel spectrogramme

---

### 6. `.gitignore`

**R√®gles d'ignorance incluses** (assure que ces fichiers ne seront pas soumis) :
- `data/` - Fichiers de base de donn√©es
- `lightning_logs/` - Fichiers checkpoint
- `generated_audio/` - Audio g√©n√©r√©
- `*.ckpt` - Tous les fichiers checkpoint

---

### 7. `matcha/data_management/ljspeech_datamodule.py`

**Optimisation du chargement des donn√©es** :
- ‚úÖ **Correction de l'erreur de sortie Ctrl+C** : R√©sout le `ConnectionResetError` qui se produit lors de la sortie de l'entra√Ænement avec `Ctrl+C`
- ‚úÖ **Cause racine** : `pin_memory=True` cr√©e un thread en arri√®re-plan `_pin_memory_loop` en environnement multi-processus, et lorsque le processus principal est interrompu, ce thread tente de lire la queue, causant une erreur de r√©initialisation de connexion
- ‚úÖ **Solution** :
  - Ajoute les param√®tres `pin_memory=False` et `persistent_workers=False` dans `LJSpeechDataModule.__init__()` (valeurs par d√©faut)
  - Applique ces param√®tres dans `DataLoader`
  - D√©finit explicitement ces param√®tres √† `False` dans `train.py`
- ‚úÖ **Impact** : √âvite les erreurs de r√©initialisation de connexion en environnement multi-processus, sortie d'entra√Ænement plus propre, impact de performance minimal pour les donn√©es de type spectrogramme mel (environ 5-15%)

---

## üîç IV. Diff√©rences principales entre la version de reproduction et la version originale

### 1. Int√©grit√© de l'architecture ‚úÖ
- **Version originale** : Architecture Matcha-TTS compl√®te
- **Version de reproduction** : Corrige tous les composants cl√©s manquants, l'architecture est align√©e avec la version originale

---

### 2. M√©thode d'impl√©mentation du code üîÑ
- **Version originale** : Utilise le syst√®me de configuration Hydra, passe les param√®tres via des fichiers de configuration
- **Version de reproduction** :
  - ‚úÖ Supporte la m√©thode d'objet de configuration originale (enti√®rement compatible)
  - ‚úÖ Supporte la m√©thode de param√®tres simplifi√©s (`n_vocab`, `out_channels`, `hidden_channels`)
  - ‚úÖ D√©tection automatique de la m√©thode √† utiliser

---

### 3. Gestion des d√©pendances üõ°Ô∏è
- **Version originale** : Suppose que toutes les d√©pendances sont disponibles
- **Version de reproduction** :
  - ‚úÖ Ajoute des m√©canismes de repli (lorsque diffusers, conformer ne sont pas disponibles)
  - ‚úÖ Ajoute un repli Python (lorsque Cython n'est pas disponible)
  - ‚úÖ Gestion d'erreurs plus robuste

---

### 4. Corrections d'erreurs üêõ
- **Version originale** : D√©j√† test√©e et valid√©e
- **Version de reproduction** :
  - ‚úÖ Corrige les probl√®mes de correspondance de taille des connexions skip
  - ‚úÖ Corrige le traitement du masque lors du sous-√©chantillonnage/sur-√©chantillonnage
  - ‚úÖ Corrige le traitement de la fonction d'activation "snake"
  - ‚úÖ Corrige les probl√®mes de configuration de l'optimiseur
  - ‚úÖ Corrige les probl√®mes de valeur de retour de TextEncoder

---

### 5. Style de code üìù
- **Version originale** : Style d'ing√©nierie utilisant Hydra + fichiers de configuration
- **Version de reproduction** :
  - ‚úÖ Maintient la logique centrale coh√©rente
  - ‚úÖ Structure du code ajust√©e (reproduction plut√¥t que copie)
  - ‚úÖ Ajoute des commentaires en fran√ßais
  - ‚úÖ Am√©liore la gestion des erreurs et l'exp√©rience utilisateur

---

### 6. Perte d'entra√Ænement üìä
- **Version originale** : Trois pertes (Duration Loss, Prior Loss, Flow Matching Loss)
- **Version de reproduction** : M√™mes trois pertes, logique d'impl√©mentation coh√©rente

---

### 7. M√©canisme d'alignement üîó
- **Version originale** : Utilise MAS (Monotonic Alignment Search)
- **Version de reproduction** : Utilise √©galement MAS, inclut un repli Python

---

### 8. R√©cup√©ration de checkpoint üíæ
- **Version originale** : N√©cessite de sp√©cifier manuellement le chemin du checkpoint
- **Version de reproduction** :
  - ‚úÖ Recherche automatique du dernier checkpoint
  - ‚úÖ Support des arguments en ligne de commande
  - ‚úÖ Gestion d'erreurs compl√®te (d√©marrage automatique depuis le d√©but s'il n'existe pas)

---

## üìä V. Statistiques des modifications

### Fichiers ajout√©s : 6
1. `matcha/utils/monotonic_align/__init__.py`
2. `matcha/utils/monotonic_align/core.pyx`
3. `matcha/utils/model.py`
4. `matcha/utils/pylogger.py`
5. `matcha/models/baselightningmodule.py`
6. `matcha/models/components/transformer.py`

---

### Compl√®tement r√©√©crits : 4
1. `matcha/models/components/text_encoder.py`
2. `matcha/models/components/decoder.py`
3. `matcha/models/components/flow_matching.py`
4. `matcha/models/matcha_tts.py`

---

### Fichiers modifi√©s : 7
1. `matcha/utils/utils.py`
2. `matcha/utils/__init__.py`
3. `matcha/__init__.py`
4. `train.py`
5. `generate.py`
6. `.gitignore` (r√®gles n√©cessaires confirm√©es incluses)
7. `matcha/data_management/ljspeech_datamodule.py`

---

## üéØ VI. R√©sum√© des am√©liorations cl√©s

### 1. Correction de l'architecture TextEncoder
- Passage du format seq-first simplifi√© au format Conv1d complet
- Ajout de composants cl√©s : DurationPredictor, RoPE, prenet, etc.
- Utilisation de MultiHeadAttention bas√© sur Conv1d

---

### 2. Correction de l'architecture Decoder
- Passage d'un simple empilement de blocs √† l'architecture U-Net compl√®te
- Ajout de connexions skip
- Correction des probl√®mes de correspondance de taille

---

### 3. Impl√©mentation Flow Matching
- Passage d'une classe de m√©thodes statiques √† la classe CFM compl√®te
- Ajout de la m√©thode solve_euler pour l'inf√©rence

---

### 4. Int√©grit√© de la perte d'entra√Ænement
- Ajout de Duration Loss et Prior Loss
- Impl√©mentation compl√®te des trois fonctions de perte

---

### 5. M√©canisme d'alignement
- Impl√©mentation de MAS (Monotonic Alignment Search)
- Remplacement de la m√©thode de sur-√©chantillonnage simple

---

### 6. Flexibilit√© et robustesse
- Supporte deux m√©thodes d'initialisation
- Ajout de m√©canismes de repli
- Am√©lioration de la gestion des erreurs

---

### 7. Exp√©rience utilisateur
- Supporte la r√©cup√©ration automatique de checkpoint
- Ajout d'arguments en ligne de commande
- Am√©lioration de la sortie des logs

---

## üìù VII. Instructions d'utilisation

### Entra√Æner le mod√®le

```bash
# Reprendre automatiquement depuis le dernier checkpoint (s'il existe)
python train.py

# Sp√©cifier un checkpoint
python train.py --checkpoint lightning_logs/version_X/checkpoints/xxx.ckpt

# Entra√Æner depuis le d√©but
python train.py --no-resume
```
---

### G√©n√©rer de l'audio

```bash
python generate.py
```

---

### Soumission Git

Assurez-vous que `.gitignore` est correctement configur√©, les fichiers/r√©pertoires suivants ne seront pas soumis :
- `data/` - Base de donn√©es
- `lightning_logs/` - Checkpoint
- `generated_audio/` - Audio g√©n√©r√©
- `*.ckpt` - Fichiers checkpoint

---

## ‚úÖ VIII. Liste de v√©rification

- [x] TextEncoder retourne trois valeurs (mu, logw, x_mask)
- [x] Decoder utilise l'architecture U-Net compl√®te
- [x] Flow Matching a une impl√©mentation CFM compl√®te
- [x] Utilise trois fonctions de perte lors de l'entra√Ænement
- [x] Utilise MAS pour l'alignement
- [x] Supporte la reprise de l'entra√Ænement depuis un checkpoint
- [x] Supporte deux m√©thodes d'initialisation
- [x] Toutes les d√©pendances ont des m√©canismes de repli
- [x] Le code est une reproduction plut√¥t qu'une copie compl√®te

---

## üîó IX. R√©f√©rences

- Matcha-TTS original : [D√©p√¥t GitHub](https://github.com/infinity-engines/Matcha-TTS)
- D√©p√¥t de ce projet : [Matcha-TTS-etu-UPMC-ENSAM](https://github.com/Raph1821/Matcha-TTS-etu-UPMC-ENSAM)

---

**Derni√®re mise √† jour** : 2025-01-XX
**Version** : Version de reproduction v1.0
